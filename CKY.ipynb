{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NOTES ON MY SOLUTIONS:\n",
        "\n",
        "*   For this assignment, I put all of the text files into a google drive and read them myself and inputted them in the methods where necessary, so you (professor) don't have to pass in the text files yourself anywhere.\n",
        "*   I have also included descriptions of how I solved each part of the problem for clarification sake\n"
      ],
      "metadata": {
        "id": "2SLikbnCuM-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 3-b grammar rules.\n",
        "!wget -q -O 3-1b_fixed.txt \"https://drive.google.com/uc?export=download&id=1KVhFPZVjptKRi8U1YCsU9Fr8FhbC3v1r\"\n",
        "PartB = open(\"/content/3-1b_fixed.txt\")\n",
        "partB = PartB.read()\n",
        "\n",
        "# Get 3-c sentences.\n",
        "!wget -q -O 3-1c_fixed.txt \"https://drive.google.com/uc?export=download&id=1yd-ZotoCF_HRJTHMkNJgUBTWMGbLDWPJ\"\n",
        "PartC = open(\"/content/3-1c_fixed.txt\")\n",
        "partC = PartC.read()\n",
        "partC = partC.split(\"\\n\")\n",
        "\n",
        "\n",
        "# Get 3-e sentences.\n",
        "!wget -q -O 3-1e_fixed.txt \"https://drive.google.com/uc?export=download&id=1Lpw8c5eVRYm-e1ldd0L__b0m_Hb4OMGs\"\n",
        "PartE = open(\"/content/3-1e_fixed.txt\")\n",
        "partE = PartE.read()\n",
        "partE = partE.split(\"\\n\")\n",
        "\n",
        "\n",
        "# Get 3-e sentences.\n",
        "!wget -q -O final-rules.txt \"https://drive.google.com/uc?export=download&id=1MxEAkcA_s-_9nT2zC6HAGeK5pcubx_HH\"\n",
        "PartErules = open(\"/content/final-rules.txt\")\n",
        "fixed_rules_e = PartErules.read()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hr1VlWwblShQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW #3a Question:** (30 points) Implement a CKY parser in your favorite programming language. The\n",
        "program should read in a  le containing CFG rules, read in input sentences and produce\n",
        "parse trees for each input sentence according to the grammar. If there are multiple\n",
        "parses for a sentence according to the grammar, then the parser should produce a count\n",
        "of the possible parses and print out all the parse trees.\n",
        "\n",
        "**My Solution:** For my solution, I created a few different methods. The general method to solve this problem is called trees and takes in a sentence and a set of rules. It then uses a method called parser_table to create two 2d arrays (one to keep track of tags and one to keep track of pointers to tags in the other array). Once the tables are filled, it calls a method called backtracking to recursively follow the pointers and find the parse of the phrase or sentence."
      ],
      "metadata": {
        "id": "JHibfV5IOFno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3a\n",
        "\n",
        "# given an input sentence, creates two 2d arrays to keep track of possible tag combinations of all words\n",
        "# returns an array of tags and an array of pointers to where the tags came from\n",
        "def parser_table(sentence, cfg_rules):\n",
        "  words = sentence.split(\" \")\n",
        "  terminal_rules = []\n",
        "  for item in cfg_rules:\n",
        "    items = item.split(\" \")\n",
        "    terminal_rules.append(items)\n",
        "  sen_length = len(words)\n",
        "  # creates two 2d arrays\n",
        "  tag_array = [[list() for i in range(sen_length)] for j in range((sen_length))]\n",
        "  # pointer array keeps track of where each tag came from\n",
        "  pointer_array = [[list() for i in range(sen_length)] for j in range((sen_length))]\n",
        "\n",
        "  # fills in the diagonal with the nonterimals corrosponding terminals\n",
        "  for j in range(0, sen_length):\n",
        "    for a in range(len(terminal_rules)):\n",
        "      if ((terminal_rules[a])[1]) == words[j]:\n",
        "        tag_array[j][j].append((terminal_rules[a])[0])\n",
        "\n",
        "  # fills in the top triangular portion of the array going col by col adding tags that match with words\n",
        "  for words in range(1, sen_length):\n",
        "    for i in range(sen_length-words):\n",
        "      j = i+words\n",
        "      for k in range(i, j):\n",
        "        for b in range(len(terminal_rules)):\n",
        "          if (len(terminal_rules[b]))>2:\n",
        "            if (len((tag_array[i][k])) > 0) and (len((tag_array[k+1][j])) > 0):\n",
        "              for a in range(0, len((tag_array[i][k]))):\n",
        "                if (terminal_rules[b])[1] == ((tag_array[i][k])[a]):\n",
        "                  for c in range(0, len((tag_array[k+1][j]))):\n",
        "                    if (terminal_rules[b])[2] == (tag_array[k+1][j])[c]:\n",
        "                      tag_array[i][j].append((terminal_rules[b])[0])\n",
        "                      location1 = a\n",
        "                      location2 = c\n",
        "                      pointer_array[i][j].append(((i, k), (location1), (k+1, j), (location2)))\n",
        "\n",
        "  # returns the tag array and the pointer array of the inputted sentence\n",
        "  # Each pointer array cell has a list of the coordinates that it points to,\n",
        "  #as well as an index of which tag in the pointed cell was used\n",
        "  return(tag_array, pointer_array)\n",
        "\n",
        "\n",
        "# This method is a recursive function that takes a starting location, recovers the tag of the location,\n",
        "# then goes to a new cell that the current location points to\n",
        "def backtracking(row, col, position):\n",
        "  # each time we get a new tag, we will add it to a string called parse\n",
        "  global parse\n",
        "  parse = parse + \" \" + \"(\"\n",
        "  # find the pointer coordinates in the cell\n",
        "  pointer1row = ((((pointer_array[row][col])[position])[0])[0])\n",
        "  pointer1col = ((((pointer_array[row][col])[position])[0])[1])\n",
        "  pointer1tag = ((pointer_array[row][col][position])[1])\n",
        "  # finds the tag in the cell\n",
        "  tag1 = (tag_array[pointer1row][pointer1col])[pointer1tag]\n",
        "\n",
        "  # if the row = col, we know we are at a nonterminal\n",
        "  if pointer1row == pointer1col:\n",
        "    # adds the tag to the parse\n",
        "    parse = parse + \" \" + (str(\"(\" + tag1 + \" \" + words[pointer1row] + \")\"))\n",
        "  else:\n",
        "    # adds the tag to the parse\n",
        "    parse = parse + \" \" + (tag1)\n",
        "\n",
        "  # if we hit a cell with a pointer, then we recursively call this function\n",
        "  if len(pointer_array[pointer1row][pointer1col]) > 0:\n",
        "    backtracking(pointer1row, pointer1col, pointer1tag)\n",
        "\n",
        "  # because each tag came from two previous tags, we have to call the function on the other pointer too\n",
        "  pointer2row = ((((pointer_array[row][col])[position])[2])[0])\n",
        "  pointer2col = (((pointer_array[row][col])[position])[2])[1]\n",
        "  pointer2tag = ((pointer_array[row][col][position])[3])\n",
        "  tag2 = (tag_array[pointer2row][pointer2col])[pointer2tag]\n",
        "\n",
        "  if pointer2row == pointer2col:\n",
        "    parse = parse + \" \" + (str(\"(\" + tag2 + \" \" + words[pointer2row] + \")\"))\n",
        "  else:\n",
        "    parse = parse + \" \" + (tag2)\n",
        "  if len(pointer_array[pointer2row][pointer2col]) > 0:\n",
        "    backtracking(pointer2row, pointer2col, pointer2tag)\n",
        "  parse = parse + (\")\")\n",
        "\n",
        "\n",
        "# This method uses helper methods to create a parse tree for each sentence in the sentences1 text file\n",
        "def trees(sentences1, rules):\n",
        "  global parse\n",
        "  global words\n",
        "  global tag_array\n",
        "  global pointer_array\n",
        "  sentences = sentences1\n",
        "  all_rules = rules\n",
        "  for i in range(len(sentences)):\n",
        "    sentence = sentences[i]\n",
        "    sentence = sentence.strip()\n",
        "    words = sentence.split(\" \")\n",
        "    # creates the 2d arrays for the cky parses\n",
        "    tag_array = parser_table(sentence, all_rules)[0]\n",
        "    pointer_array = parser_table(sentence, all_rules)[1]\n",
        "\n",
        "    # uses backtracking to find all the parses\n",
        "    parse_count = 0\n",
        "    print(\"\\n\")\n",
        "    print(sentence)\n",
        "    for k in range(len(tag_array[0][len(words)-1])):\n",
        "      parse_count = parse_count+1\n",
        "      first_tag = (tag_array[0][len(words)-1])[k]\n",
        "      parse = \"\"\n",
        "      parse = parse + (first_tag)\n",
        "      backtracking(0, (len(words)-1), k)\n",
        "      print(\"parse\" + str(k+1)+ \":\")\n",
        "      print(parse)\n",
        "    print(\"parse count: \" + str(parse_count))\n",
        "\n",
        "\n",
        "'''\n",
        "file2 = '/content/3-1c.txt'\n",
        "sentences = open(file2, 'r')\n",
        "sentences = sentences.read()\n",
        "sentences = sentences.split(\"\\n\")\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "orbi0o8gIG5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "416b8d16-597d-431b-d5a8-297be4e0fe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfile2 = \\'/content/3-1c.txt\\'\\nsentences = open(file2, \\'r\\')\\nsentences = sentences.read()\\nsentences = sentences.split(\"\\n\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW #3b Question:** (10 points) Write a program to convert the grammar in  le \\3-1b.txt\" to Chomsky\n",
        "Normal Form. Your program does not have to be general CNF convertor for all CFGs.\n",
        "The grammar rules have the format left hand side symbol followed by a list of right hand\n",
        "side symbols. \\S\" is the start symbol for the grammar. Words that are in lowercase are\n",
        "terminal symbols of the grammar.\n",
        "\n",
        "**My Solution**: For my solution, I created a method that reads in a list of rules one by one. First, it checks for any rules that are unit rules of length two replaces that rule with new rules that account for the old rule. Then it loops through the rules again to check for any rules with a right side greater than 2 and replaces it with new rules by creating new variables"
      ],
      "metadata": {
        "id": "0Vr2DPxNNT_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3b:\n",
        "'''\n",
        "file1 = '/content/Final-Rules.txt'\n",
        "rule_list = open(file1, 'r')\n",
        "rule_list = rule_list.read()\n",
        "'''\n",
        "# method to convert the grammer to cfg format\n",
        "def cfg_converter(rule_list):\n",
        "  all_rules = []\n",
        "  rule_list_split = rule_list.split(\"\\n\")\n",
        "  for i in range(len(rule_list_split)):\n",
        "    all_rules.append(rule_list_split[i])\n",
        "\n",
        "  # loop to go through the list of rules and find ones of length two\n",
        "  i = 0;\n",
        "  while (True):\n",
        "    if (i > (len(all_rules)-1)):\n",
        "      break\n",
        "    words = all_rules[i].split(\" \")\n",
        "    if len(words) == 2 and not words[1].islower():\n",
        "      for j in range(len(all_rules)):\n",
        "        cur_rule = all_rules[j].split(\" \")\n",
        "        # if we find a rule that begins with the nonterminal\n",
        "        if words[1] == cur_rule[0]:\n",
        "          # create a new rule to replace it\n",
        "          if (len(cur_rule)) == 2:\n",
        "            new_rule = words[0]+ \" \" + cur_rule[1]\n",
        "          else:\n",
        "            new_rule = words[0] + \" \" + cur_rule[1] + \" \" + cur_rule[2]\n",
        "          all_rules.append(new_rule)\n",
        "      all_rules.remove(all_rules[i])\n",
        "    else:\n",
        "      i = i+1\n",
        "\n",
        "  # loop to go through the list of rules and find ones of length four\n",
        "  i = 0\n",
        "  v = 0\n",
        "  while (True):\n",
        "    var1 = \"X\"\n",
        "    if (i > (len(all_rules)-1)):\n",
        "      break\n",
        "    words = all_rules[i].split(\" \")\n",
        "    if len(words) == 4:\n",
        "      # creates a new variable and splits up the rule so it is of length 3\n",
        "      new_rule = words[0] + \" \" + str(v) + \" \" + words[3]\n",
        "      new_rule2 = str(v) + \" \" + words[1] + \" \" + words[2]\n",
        "      all_rules.append(new_rule)\n",
        "      all_rules.append(new_rule2)\n",
        "      all_rules.remove(all_rules[i])\n",
        "      v = v+1\n",
        "    else:\n",
        "      i = i+1\n",
        "      v = v+1\n",
        "\n",
        "  # deletes any repetative rules\n",
        "  index = 0\n",
        "  while (True):\n",
        "    if (index > (len(all_rules)-1)):\n",
        "      break\n",
        "    if (all_rules.count(all_rules[index]) > 1):\n",
        "      all_rules.remove(all_rules[index])\n",
        "    index = index+1\n",
        "\n",
        "  return all_rules\n",
        "\n",
        "\n",
        "print(cfg_converter(partB))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IBcn95AYR_J",
        "outputId": "883c42b3-188f-44ee-ff4b-b8d8839436dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S NP VP', 'NP Det NBar', 'NP NP PP', 'NBar N NBar', 'PP Prep NP', 'VP V NP', 'VP VP PP', 'Prep with', 'Prep on', 'Prep in', 'Prep at', 'Prep like', 'Adj green', 'Adj light', 'N light', 'N car', 'N cars', 'N truck', 'N man', 'N baby', 'Det the', 'Det a', 'V fly', 'V hit', 'V gave', 'V put', 'V like', 'COMP that', 'CONJ and', 'NP N NBar', 'NBar light', 'NBar car', 'NBar cars', 'NBar truck', 'NBar man', 'NBar baby', 'VP fly', 'VP hit', 'VP gave', 'VP put', 'VP like', 'NP light', 'NP car', 'NP cars', 'NP truck', 'NP man', 'NP baby', 'NP 1 NBar', '1 Det Adj', 'VP 7 NP', '7 V NP', 'VP 8 PP', '8 V NP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question: HW#C (20 points)** Using the converted grammar from 1(b) parse the sentences in \\3-1c.txt\"\n",
        "using your CKY parser. Your program should output (a) the number of parses and (b)\n",
        "all parse trees for each sentence. You may output parse trees as indented lines; you don't\n",
        "have to draw pretty trees.\n",
        "\n",
        "**My Solution:** To implement my solution, I simply converted the grammar from part B to CNF and then plugged in the sentences to my method from A to print out all the possible trees and parses"
      ],
      "metadata": {
        "id": "lxNUcwCzwIy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Part C\n",
        "\n",
        "# calls the grammer converter and the method that creates the parsing trees\n",
        "all_rules = cfg_converter(partB)\n",
        "trees(partC, all_rules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ76ZdO8uiiE",
        "outputId": "669b050d-ac24-43f0-8b4b-cf6277f269d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "light cars fly\n",
            "parse1:\n",
            "S ( NP ( (N light) (NBar cars)) (VP fly))\n",
            "parse count: 1\n",
            "\n",
            "\n",
            "light green cars fly\n",
            "parse count: 0\n",
            "\n",
            "\n",
            "the man gave a baby a car\n",
            "parse1:\n",
            "S ( NP ( (Det the) (NBar man)) VP ( 7 ( (V gave) NP ( (Det a) (NBar baby))) NP ( (Det a) (NBar car))))\n",
            "parse count: 1\n",
            "\n",
            "\n",
            "the baby put the man on the truck\n",
            "parse1:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( (V put) NP ( NP ( (Det the) (NBar man)) PP ( (Prep on) NP ( (Det the) (NBar truck))))))\n",
            "parse2:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( VP ( (V put) NP ( (Det the) (NBar man))) PP ( (Prep on) NP ( (Det the) (NBar truck)))))\n",
            "parse3:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( 8 ( (V put) NP ( (Det the) (NBar man))) PP ( (Prep on) NP ( (Det the) (NBar truck)))))\n",
            "parse count: 3\n",
            "\n",
            "\n",
            "the baby hit the truck with the car\n",
            "parse1:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( (V hit) NP ( NP ( (Det the) (NBar truck)) PP ( (Prep with) NP ( (Det the) (NBar car))))))\n",
            "parse2:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( VP ( (V hit) NP ( (Det the) (NBar truck))) PP ( (Prep with) NP ( (Det the) (NBar car)))))\n",
            "parse3:\n",
            "S ( NP ( (Det the) (NBar baby)) VP ( 8 ( (V hit) NP ( (Det the) (NBar truck))) PP ( (Prep with) NP ( (Det the) (NBar car)))))\n",
            "parse count: 3\n",
            "\n",
            "\n",
            "the man at the light green light put the baby in a car\n",
            "parse count: 0\n",
            "\n",
            "\n",
            "cars like a truck like a light baby\n",
            "parse1:\n",
            "S ( (NP cars) VP ( (V like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby)))))))\n",
            "parse2:\n",
            "S ( (NP cars) VP ( (V like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( 1 ( (Det a) (Adj light)) (NBar baby))))))\n",
            "parse3:\n",
            "S ( (NP cars) VP ( VP ( (V like) NP ( (Det a) (NBar truck))) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby))))))\n",
            "parse4:\n",
            "S ( (NP cars) VP ( VP ( (V like) NP ( (Det a) (NBar truck))) PP ( (Prep like) NP ( 1 ( (Det a) (Adj light)) (NBar baby)))))\n",
            "parse5:\n",
            "S ( (NP cars) VP ( 8 ( (V like) NP ( (Det a) (NBar truck))) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby))))))\n",
            "parse6:\n",
            "S ( (NP cars) VP ( 8 ( (V like) NP ( (Det a) (NBar truck))) PP ( (Prep like) NP ( 1 ( (Det a) (Adj light)) (NBar baby)))))\n",
            "parse7:\n",
            "S ( (NP cars) VP ( 7 ( (V like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( (Det a) (NBar light))))) (NP baby)))\n",
            "parse8:\n",
            "NP ( (NP cars) PP ( (Prep like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby)))))))\n",
            "parse9:\n",
            "NP ( (NP cars) PP ( (Prep like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( 1 ( (Det a) (Adj light)) (NBar baby))))))\n",
            "parse10:\n",
            "S ( NP ( (NP cars) PP ( (Prep like) NP ( (Det a) (NBar truck)))) VP ( (V like) NP ( (Det a) NBar ( (N light) (NBar baby)))))\n",
            "parse11:\n",
            "S ( NP ( (NP cars) PP ( (Prep like) NP ( (Det a) (NBar truck)))) VP ( (V like) NP ( 1 ( (Det a) (Adj light)) (NBar baby))))\n",
            "parse12:\n",
            "S ( NP ( (NP cars) PP ( (Prep like) NP ( (Det a) (NBar truck)))) VP ( 7 ( (V like) NP ( (Det a) (NBar light))) (NP baby)))\n",
            "parse13:\n",
            "NP ( NP ( (NP cars) PP ( (Prep like) NP ( (Det a) (NBar truck)))) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby)))))\n",
            "parse14:\n",
            "NP ( NP ( (NP cars) PP ( (Prep like) NP ( (Det a) (NBar truck)))) PP ( (Prep like) NP ( 1 ( (Det a) (Adj light)) (NBar baby))))\n",
            "parse count: 14\n",
            "\n",
            "\n",
            "a light baby hit a green man with a truck in the car\n",
            "parse1:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car))))))))\n",
            "parse2:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( (V hit) NP ( NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car))))))\n",
            "parse3:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( VP ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car)))))))\n",
            "parse4:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( 8 ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car)))))))\n",
            "parse5:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( VP ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck))))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse6:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( VP ( VP ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse7:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( VP ( 8 ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse8:\n",
            "S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( 8 ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck))))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse9:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car))))))))\n",
            "parse10:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( (V hit) NP ( NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car))))))\n",
            "parse11:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( VP ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car)))))))\n",
            "parse12:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( 8 ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car)))))))\n",
            "parse13:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( VP ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck))))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse14:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( VP ( VP ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse15:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( VP ( 8 ( (V hit) NP ( 1 ( (Det a) (Adj green)) (NBar man))) PP ( (Prep with) NP ( (Det a) (NBar truck)))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse16:\n",
            "S ( NP ( 1 ( (Det a) (Adj light)) (NBar baby)) VP ( 8 ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( (Det a) (NBar truck))))) PP ( (Prep in) NP ( (Det the) (NBar car)))))\n",
            "parse count: 16\n",
            "\n",
            "\n",
            "a light green car that hit the truck with cars and a baby\n",
            "parse count: 0\n",
            "\n",
            "\n",
            "a green light car truck hit a baby a man\n",
            "parse1:\n",
            "S ( NP ( 1 ( (Det a) (Adj green)) NBar ( (N light) NBar ( (N car) (NBar truck)))) VP ( 7 ( (V hit) NP ( (Det a) (NBar baby))) NP ( (Det a) (NBar man))))\n",
            "parse count: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW3d Question:** (20 points) Some sentences in \\3-1c.txt\" cannot be parsed by the grammar. Extend\n",
        "your parser to recover the set of partial parses that span the sentence. Partial parses\n",
        "are parses for substrings of the input. A partial parse that spans the most number of\n",
        "tokens is a longest spanning partial parse. A set of partial parses is needed to span all\n",
        "the tokens of a sentence. You can use a greedy approach to selecting the partial parse\n",
        "to be included in the set.\n",
        "\n",
        "**My Solution**: To implement my solution, I created a method to find a set of parses of a sentence with the longest partial parse. I first called the parse_table method to fill in all possible parses into a table and then I traversed the table from the top right cell to find the longest partial parse by looking at the cells that account for the most amount of words. Then, I called the backpointer method recursively to get a parse for the partial sentence. Then I recursively called my solution on the rest of the sentence (both sides that aren't acocunted for by the parse) The first parse in the list is the longest partial parse. If a sentence parses completely, I simply printed out the parse"
      ],
      "metadata": {
        "id": "t_jbmzoZO0mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3d:\n",
        "\n",
        "# final_parse will eventually be a string with each longest possible partial parse\n",
        "final_parse = \"\"\n",
        "\n",
        "# This method is similar to trees, but now returns all partial parses. It calls 2 helper methods\n",
        "def trees2(sentences1, rules):\n",
        "  global parse\n",
        "  global words\n",
        "  global tag_array\n",
        "  global pointer_array\n",
        "  global final_parse\n",
        "  sentence = sentences1\n",
        "  all_rules = rules\n",
        "  words = sentence.split(\" \")\n",
        "  # creates the 2d arrays for the given part of the sentence\n",
        "  tag_array = parser_table(sentence, all_rules)[0]\n",
        "  pointer_array = parser_table(sentence, all_rules)[1]\n",
        "\n",
        "  # diagonally searches from the top right corner until it hits a cell with a tag\n",
        "  k = 0\n",
        "  var1 = True\n",
        "  for i in reversed(range(len(words))):\n",
        "    if (var1 == False):\n",
        "      break\n",
        "    k = k+1\n",
        "    for l in range(0,k):\n",
        "      if (var1 == False):\n",
        "        break\n",
        "      if (len(tag_array[l][i+l]) >0):\n",
        "\n",
        "        # once it hits a cell with a tag, it finds the parse of the words accounted for by the cell\n",
        "        var1 = False\n",
        "        first_tag = (tag_array[l][i+l])[0]\n",
        "        parse = \"\"\n",
        "        parse = parse + (first_tag)\n",
        "        # determines whether this tag is a terminal or a nonterminal\n",
        "        if (l==i+l):\n",
        "          final_parse = final_parse + \" \\nPartial parse: \" + \" (\" + first_tag + \" \" + words[l] + \")\"\n",
        "        else:\n",
        "          # if it is a nonterminal, it backtracks to find the parse\n",
        "          final_parse = final_parse + \" \\nPartial parse: \"\n",
        "          backtracking(l, (i+l), 0)\n",
        "          final_parse = final_parse + parse\n",
        "        new_part = \"\"\n",
        "        new_part2 = \"\"\n",
        "\n",
        "        # To get the rest of the sentence, recurseively call this method on\n",
        "        # every part of the sentence not accounted for by these words\n",
        "        for v in range(0, l):\n",
        "          if (v == 0):\n",
        "            new_part = words[v]\n",
        "          else:\n",
        "            new_part = new_part + \" \" + words[v]\n",
        "        for x in range(i+l+1, len(words)):\n",
        "          if (x == 0):\n",
        "            new_part2 = words[x]\n",
        "          else:\n",
        "            new_part2 = new_part2 + \" \" + words[x]\n",
        "        if (len(new_part) >0):\n",
        "          trees2(new_part, all_rules)\n",
        "        if (len(new_part2) >0):\n",
        "          trees2(new_part2, all_rules)\n",
        "        return (final_parse)\n",
        "\n",
        "\n",
        "# converts the rules\n",
        "the_rules = cfg_converter(partB)\n",
        "\n",
        "# calls the partial parser tree method on each sentence\n",
        "for i in range(len(partC)):\n",
        "  sentencetest = partC[i]\n",
        "  print(\"sentence: \" + sentencetest)\n",
        "  print(trees2(sentencetest, the_rules))\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  final_parse = \"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN4fzrn8Kzvd",
        "outputId": "73d36799-1506-4766-bc8e-9c11072e670a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence: light cars fly\n",
            " \n",
            "Partial parse: S ( NP ( (N light) (NBar cars)) (VP fly))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: light green cars fly\n",
            " \n",
            "Partial parse: S ( (NP cars) (VP fly)) \n",
            "Partial parse:  (Adj light) \n",
            "Partial parse:  (Adj green)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the man gave a baby a car\n",
            " \n",
            "Partial parse: S ( NP ( (Det the) (NBar man)) VP ( 7 ( (V gave) NP ( (Det a) (NBar baby))) NP ( (Det a) (NBar car))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the baby put the man on the truck\n",
            " \n",
            "Partial parse: S ( NP ( (Det the) (NBar baby)) VP ( (V put) NP ( NP ( (Det the) (NBar man)) PP ( (Prep on) NP ( (Det the) (NBar truck))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the baby hit the truck with the car\n",
            " \n",
            "Partial parse: S ( NP ( (Det the) (NBar baby)) VP ( (V hit) NP ( NP ( (Det the) (NBar truck)) PP ( (Prep with) NP ( (Det the) (NBar car))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the man at the light green light put the baby in a car\n",
            " \n",
            "Partial parse: S ( (NP light) VP ( (V put) NP ( NP ( (Det the) (NBar baby)) PP ( (Prep in) NP ( (Det a) (NBar car)))))) \n",
            "Partial parse: NP ( NP ( (Det the) (NBar man)) PP ( (Prep at) NP ( (Det the) (NBar light)))) \n",
            "Partial parse:  (Adj green)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: cars like a truck like a light baby\n",
            " \n",
            "Partial parse: S ( (NP cars) VP ( (V like) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep like) NP ( (Det a) NBar ( (N light) (NBar baby)))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: a light baby hit a green man with a truck in the car\n",
            " \n",
            "Partial parse: S ( NP ( (Det a) NBar ( (N light) (NBar baby))) VP ( (V hit) NP ( NP ( 1 ( (Det a) (Adj green)) (NBar man)) PP ( (Prep with) NP ( NP ( (Det a) (NBar truck)) PP ( (Prep in) NP ( (Det the) (NBar car))))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: a light green car that hit the truck with cars and a baby\n",
            " \n",
            "Partial parse: VP ( (V hit) NP ( NP ( (Det the) (NBar truck)) PP ( (Prep with) (NP cars)))) \n",
            "Partial parse: NP ( (Det a) (NBar light)) \n",
            "Partial parse:  (Adj green) \n",
            "Partial parse:  (N car) \n",
            "Partial parse:  (COMP that) \n",
            "Partial parse: NP ( (Det a) (NBar baby)) \n",
            "Partial parse:  (CONJ and)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: a green light car truck hit a baby a man\n",
            " \n",
            "Partial parse: S ( NP ( 1 ( (Det a) (Adj green)) NBar ( (N light) NBar ( (N car) (NBar truck)))) VP ( 7 ( (V hit) NP ( (Det a) (NBar baby))) NP ( (Det a) (NBar man))))\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question HW3(e) (20 points):** How will you \\ x\" the grammar in a general way so that the ungrammatical\n",
        "sentences in \\3-1e.txt\" do not parse? Show the rules of the \\ xed\" grammar, run your\n",
        "parser with the  xed grammar to show that the ungrammatical sentences do not parse\n",
        "(produce their partial parses instead). Explain what you did to  x the grammar and the\n",
        "rationale for what you did.\n",
        "\n",
        "**My Solution:** To fix the grammar, I realized that these sentences have three problems. The first one needs to account for singular and plural differences. The second one needs to account for the fact that some verbs are transitive and only take one argument. The third sentence needs the rules to account for the fact that some verbs are ditransitive and take two arguements.\n",
        "\n",
        "To address these needs, I assigned all N, NBar, and NP as singular or plural. I then assigned all revelent verbs as singular or plural as well. Then, I assigned the verbs as transitive or ditransitive. This made me have a lot more terminals in my rule list. Because of this, I now had to change all the subsequent rules so that Ns, NBars, and NPs were only matching up with Vs and VPs that had the same plurality as them. I also changed all subsequent rules so that V, and VP would only take the relevent amount of arguments. To do this, I needed to specify whether an NP had two arguments or one, which affected the VPs that it was allowed to combine with. In my results, it is clear that the partial parses couldn't combine with each other because of the reasons listed above."
      ],
      "metadata": {
        "id": "harH1xSsxHh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part e:\n",
        "\n",
        "# converts the new rules to CNF\n",
        "new_rules = cfg_converter(fixed_rules_e)\n",
        "\n",
        "# goes through every sentence in parte and prints their partial parses\n",
        "for i in range(len(partE)):\n",
        "  sentencetest = partE[i]\n",
        "  print(\"sentence: \" + sentencetest)\n",
        "  print(trees2(sentencetest, new_rules))\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  final_parse = \"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuLjPZFcicF-",
        "outputId": "14ffcf18-bf5a-407b-df07-d444dd919c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence: the car fly\n",
            " \n",
            "Partial parse: NP.sg.arg1 ( (Det the) (NBar.sg car)) \n",
            "Partial parse:  (V.pl fly)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the truck hit the baby the car\n",
            " \n",
            "Partial parse: S ( NP.sg.arg1 ( (Det the) (NBar.sg truck)) VP.sg.trans ( (V.trans hit) NP.sg.arg1 ( (Det the) (NBar.sg baby)))) \n",
            "Partial parse: NP.sg.arg1 ( (Det the) (NBar.sg car))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentence: the man put the baby\n",
            " \n",
            "Partial parse: NP.sg.arg1 ( (Det the) (NBar.sg man)) \n",
            "Partial parse: NP.sg.arg1 ( (Det the) (NBar.sg baby)) \n",
            "Partial parse:  (V.ditrans put)\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}